{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK_xW9gR6bta"
      },
      "source": [
        "# Task 1 : Set up colab gpu runtime environment"
      ],
      "id": "RK_xW9gR6bta"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trj2m5ohqPY8"
      },
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
        "!pip install --upgrade opencv-contrib-python"
      ],
      "id": "Trj2m5ohqPY8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kVJz-wpTERY"
      },
      "source": [
        "# Download Dataset"
      ],
      "id": "7kVJz-wpTERY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKFIZ8IlTDgT"
      },
      "source": [
        "pip install kaggle"
      ],
      "id": "jKFIZ8IlTDgT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your kaggle API Key as kaggle.json\n",
        "# Then run the codes below"
      ],
      "metadata": {
        "id": "eI8kf5KJvEa1"
      },
      "id": "eI8kf5KJvEa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0Y2aSJSWtFNb"
      },
      "id": "0Y2aSJSWtFNb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tapakah68/supervisely-filtered-segmentation-person-dataset"
      ],
      "metadata": {
        "id": "QgxnJejJufeF"
      },
      "id": "QgxnJejJufeF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip supervisely-filtered-segmentation-person-dataset.zip"
      ],
      "metadata": {
        "id": "sGdw70UWvWuH"
      },
      "id": "sGdw70UWvWuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrange dataset folder name and location\n",
        "import shutil\n",
        "import os\n",
        "source_folder = 'supervisely_person_clean_2667_img/supervisely_person_clean_2667_img'\n",
        "des_folder = 'person-dataset'\n",
        "shutil.move(source_folder, des_folder)\n",
        "os.rmdir('supervisely_person_clean_2667_img')\n"
      ],
      "metadata": {
        "id": "f8pSwlGw60JZ"
      },
      "id": "f8pSwlGw60JZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "compliant-gossip"
      },
      "source": [
        "# Some Common Imports"
      ],
      "id": "compliant-gossip"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F7rW6SNTn5r"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/person_dataset')"
      ],
      "id": "0F7rW6SNTn5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlikely-winner"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "id": "unlikely-winner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function for showing images:"
      ],
      "metadata": {
        "id": "6dNUrLGL8Xqx"
      },
      "id": "6dNUrLGL8Xqx"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def show_image(image,mask,pred_image = None):\n",
        "\n",
        "    if pred_image == None:\n",
        "\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "\n",
        "        ax1.set_title('IMAGE')\n",
        "        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n",
        "\n",
        "        ax2.set_title('GROUND TRUTH')\n",
        "        ax2.imshow(mask.permute(1,2,0).squeeze(),cmap = 'gray')\n",
        "\n",
        "    elif pred_image != None :\n",
        "\n",
        "        f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(10,5))\n",
        "\n",
        "        ax1.set_title('IMAGE')\n",
        "        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')\n",
        "\n",
        "        ax2.set_title('GROUND TRUTH')\n",
        "        ax2.imshow(mask.permute(1,2,0).squeeze(),cmap = 'gray')\n",
        "\n",
        "        ax3.set_title('MODEL OUTPUT')\n",
        "        ax3.imshow(pred_image.permute(1,2,0).squeeze(),cmap = 'gray')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dx9OMIr-3Bts"
      },
      "id": "dx9OMIr-3Bts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moved-bottle"
      },
      "source": [
        "# Task : 2 Setup Configurations"
      ],
      "id": "moved-bottle"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "interim-grant"
      },
      "source": [
        "DATA_DIR = '/content/'\n",
        "\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "EPOCHS = 25\n",
        "\n",
        "# Learning Rate\n",
        "LR = 0.003\n",
        "\n",
        "IMAGE_SIZE = 320\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "ENCODER = 'timm-efficientnet-b0'\n",
        "WEIGHTS = 'imagenet'"
      ],
      "id": "interim-grant",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_folder = 'person-dataset/images/'\n",
        "masks_folder = 'person-dataset/masks/'\n",
        "\n",
        "image_files = sorted(os.listdir(images_folder))\n",
        "mask_files = sorted(os.listdir(masks_folder))\n",
        "\n",
        "data = {'images': [os.path.join(images_folder, filename) for filename in image_files],\n",
        "        'masks': [os.path.join(masks_folder, filename) for filename in mask_files]}\n",
        "\n",
        "### optional: save as csv file###\n",
        "#df = pd.DataFrame(data)\n",
        "#df.to_csv('df.csv', index=False)"
      ],
      "metadata": {
        "id": "UEwnwxxKRINC"
      },
      "id": "UEwnwxxKRINC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "gMO4rI191pwk"
      },
      "id": "gMO4rI191pwk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-conducting"
      },
      "source": [
        "row = df.iloc[150]\n",
        "\n",
        "image_path = row.images\n",
        "mask_path = row.masks\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0"
      ],
      "id": "anonymous-conducting",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "superb-belle"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
        "\n",
        "ax1.set_title('IMAGE')\n",
        "ax1.imshow(image)\n",
        "\n",
        "ax2.set_title('GROUND TRUTH')\n",
        "ax2.imshow(mask,cmap = 'gray')"
      ],
      "id": "superb-belle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fabulous-peripheral"
      },
      "source": [
        "train_df, valid_df = train_test_split(df, test_size = 0.2, random_state = 42)"
      ],
      "id": "fabulous-peripheral",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fancy-knock"
      },
      "source": [
        "# Task 3 : Augmentation Functions"
      ],
      "id": "fancy-knock"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "further-vietnamese"
      },
      "source": [
        "albumentation documentation : https://albumentations.ai/docs/"
      ],
      "id": "further-vietnamese"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rocky-pavilion"
      },
      "source": [
        "import albumentations as A"
      ],
      "id": "rocky-pavilion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "possible-cinema"
      },
      "source": [
        "def get_train_augs():\n",
        "  return A.Compose([\n",
        "      A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
        "      A.HorizontalFlip(p = 0.5),\n",
        "      A.VerticalFlip(p = 0.5)\n",
        "  ], is_check_shapes=False)\n",
        "\n",
        "def get_valid_augs():\n",
        "  return A.Compose([\n",
        "    A.Resize(IMAGE_SIZE, IMAGE_SIZE)\n",
        "], is_check_shapes=False)"
      ],
      "id": "possible-cinema",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceramic-closer"
      },
      "source": [
        "# Task 4 : Create Custom Dataset"
      ],
      "id": "ceramic-closer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-wagon"
      },
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "id": "anonymous-wagon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rubber-humanitarian"
      },
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, df, augmentations):\n",
        "    self.df = df\n",
        "    self.augmentations = augmentations\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "\n",
        "    image_path = row.images\n",
        "    mask_path = row.masks\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = np.expand_dims(mask, axis = -1)\n",
        "\n",
        "    if self.augmentations:\n",
        "      data = self.augmentations(image = image, mask = mask)\n",
        "      image = data['image']\n",
        "      mask = data['mask']\n",
        "\n",
        "    # (h, w, c) -> (c, h, w)\n",
        "    image = np.transpose(image, (2,0,1)).astype(np.float32)\n",
        "    mask = np.transpose(mask, (2,0,1)).astype(np.float32)\n",
        "\n",
        "    # np to tensor\n",
        "    image = torch.Tensor(image) / 255.0\n",
        "    mask = torch.round(torch.Tensor(mask) / 255.0)\n",
        "\n",
        "    return image, mask"
      ],
      "id": "rubber-humanitarian",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "looking-lightning"
      },
      "source": [
        "trainset = SegmentationDataset(train_df, get_train_augs())\n",
        "validset = SegmentationDataset(valid_df, get_valid_augs())"
      ],
      "id": "looking-lightning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gothic-extreme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75396164-3ed6-4146-f9ee-157834a5919b"
      },
      "source": [
        "print(f\"Size of Trainset : {len(trainset)}\")\n",
        "print(f\"Size of Validset : {len(validset)}\")"
      ],
      "id": "gothic-extreme",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Trainset : 2133\n",
            "Size of Validset : 534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aging-being"
      },
      "source": [
        "idx = 150\n",
        "image, mask = trainset[idx]\n",
        "show_image(image, mask)"
      ],
      "id": "aging-being",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "impossible-literature"
      },
      "source": [
        "# Task 5 : Load dataset into batches"
      ],
      "id": "impossible-literature"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "honey-paraguay"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "id": "honey-paraguay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lesbian-terror"
      },
      "source": [
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle = True)\n",
        "valid_loader = DataLoader(validset, batch_size=BATCH_SIZE)"
      ],
      "id": "lesbian-terror",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saved-blend"
      },
      "source": [
        "print(f\"Total number of batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Total number of batches in valid_loader: {len(valid_loader)}\")"
      ],
      "id": "saved-blend",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heard-nightmare"
      },
      "source": [
        "for image, mask in train_loader:\n",
        "  break\n",
        "print(f\"One batch image shape: {image.shape}\")\n",
        "print(f\"One batch mask shape: {mask.shape}\")\n",
        "\n",
        "# batch_size, channel, height, width"
      ],
      "id": "heard-nightmare",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiscal-genome"
      },
      "source": [
        "# Task 6 : Create Segmentation Model"
      ],
      "id": "fiscal-genome"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opening-benefit"
      },
      "source": [
        "segmentation_models_pytorch documentation : https://smp.readthedocs.io/en/latest/"
      ],
      "id": "opening-benefit"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "protected-emphasis"
      },
      "source": [
        "from torch import nn\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.losses import DiceLoss"
      ],
      "id": "protected-emphasis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stopped-treaty"
      },
      "source": [
        "class SegmentationModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SegmentationModel, self).__init__()\n",
        "\n",
        "    #architecture\n",
        "    self.arc = smp.Unet(\n",
        "        encoder_name = ENCODER,\n",
        "        encoder_weights = WEIGHTS,\n",
        "        in_channels = 3,\n",
        "        classes = 1,\n",
        "        activation = None\n",
        "    )\n",
        "  def forward(self, images, masks=None):\n",
        "    logits = self.arc(images)\n",
        "\n",
        "    if masks != None:\n",
        "      loss1 = DiceLoss(mode='binary')(logits, masks)\n",
        "      loss2 = nn.BCEWithLogitsLoss()(logits, masks)\n",
        "      return logits, loss1 + loss2\n",
        "    return logits\n",
        "\n"
      ],
      "id": "stopped-treaty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "christian-settlement"
      },
      "source": [
        "model = SegmentationModel()\n",
        "model.to(DEVICE)"
      ],
      "id": "christian-settlement",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "threaded-bracket"
      },
      "source": [
        "# Task 7 : Create Train and Validation Function"
      ],
      "id": "threaded-bracket"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alone-voltage"
      },
      "source": [
        "def train_fn(data_loader, model, optimizer):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for images, masks in tqdm(data_loader):\n",
        "    images = images.to(DEVICE)\n",
        "    masks = masks.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits, loss = model(images, masks)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  # average loss\n",
        "  return total_loss / len(data_loader)"
      ],
      "id": "alone-voltage",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whole-musician"
      },
      "source": [
        "def eval_fn(data_loader, model):\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for images, masks in tqdm(data_loader):\n",
        "      images = images.to(DEVICE)\n",
        "      masks = masks.to(DEVICE)\n",
        "\n",
        "      logits, loss = model(images, masks)\n",
        "\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "  # average loss\n",
        "  return total_loss / len(data_loader)"
      ],
      "id": "whole-musician",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "primary-variance"
      },
      "source": [
        "# Task 8 : Train Model"
      ],
      "id": "primary-variance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floral-france"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
      ],
      "id": "floral-france",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mounted-sword"
      },
      "source": [
        "best_valid_loss = np.Inf\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  train_loss = train_fn(train_loader, model, optimizer)\n",
        "  valid_loss = eval_fn(valid_loader, model)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), 'best_model.pt')\n",
        "    print(\"Saved Model\")\n",
        "    best_valid_loss = valid_loss\n",
        "\n",
        "  print(f\"Epoch: {i+1} Train Loss: {train_loss} Valid Loss: {valid_loss}\")"
      ],
      "id": "mounted-sword",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVVzhk0HupfA"
      },
      "source": [
        "# Task 9 : Inference"
      ],
      "id": "CVVzhk0HupfA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seventh-seating"
      },
      "source": [
        "idx = 10\n",
        "\n",
        "model.load_state_dict(torch.load('/content/best_model.pt'))\n",
        "\n",
        "image, mask = validset[idx]\n",
        "\n",
        "logits_mask = model(image.to(DEVICE).unsqueeze(0)) # (C, H, W) -> (1, C, H, W)\n",
        "pred_mask = torch.sigmoid(logits_mask)\n",
        "pred_mask = (pred_mask > 0.5) * 1.0"
      ],
      "id": "seventh-seating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "divided-mustang"
      },
      "source": [
        "show_image(image, mask, pred_mask.detach().cpu().squeeze(0))"
      ],
      "id": "divided-mustang",
      "execution_count": null,
      "outputs": []
    }
  ]
}